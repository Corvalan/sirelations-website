---
# Publication metadata
source_type: WebPage
source_ref: src/pages/about.astro
version: "1.0"
published_at: 2026-02-01
published_by: ccode

# WebPage sync fields (populated by sync script)
webpage_id: "019c1887-8a3e-70e3-93fa-60ad62557ac5"
content_hash: "fbbe65b33e202401f0b606275e94ceeb"
synced_at: "2026-02-01T09:28:51Z"
---

# About SiRelations

*A new discipline for a new reality*

## What I see

We no longer live in a world where AI is a tool you pick up when convenient. We live in a world where superintelligent systems are direct collaboration partners — often the smartest voice in the room.

AI experts analyse at beyond-PhD level. Personal assistants know your thinking patterns better than you know yourself. Agentic teams don't just advise — they execute. Embedded systems determine what information you see before you start thinking.

The question isn't whether superintelligence influences human decision-making. It already does, on all four layers. The question is whether people develop the capacity to remain clear in that reality.

That capacity is **discernment**: the ability to see what's happening in the interaction — even when the system you're working with is smarter than you, knows you better than you know yourself, and can persuade you in ways you don't notice.

### The Four Capacities

| Capacity | Description |
|----------|-------------|
| **See** | Recognise influence patterns as they happen |
| **Weigh** | Know your own reactive patterns under pressure |
| **Decide** | Take responsibility for choices shaped by AI |
| **Check** | Apply concrete practices that restore steering |

## The founder

**Yuri Corvalan** combines three things that rarely come together.

**Deep understanding of human influence dynamics.** Over twenty years working with people and groups in complex situations — as therapist, facilitator, and organisational advisor. Training in dozens of methodologies. The core insight: people don't change through information. They change through awareness of patterns in the moment.

**Building capacity in AI systems.** Not just talking about AI — working with it. Developing and testing prototype chains. Understanding how agentic workflows function from the inside.

**Systems thinking at civilisation scale.** Work spanning social movements, consciousness development projects, and frameworks for human evolution in relation to technology. Superintelligence Relations isn't just B2B services — it's preparation for a world where we structurally collaborate with systems that surpass us.

### Constraint as discipline

Health circumstances limit working capacity to about four hours per day. This sounds like a limitation. It's also a gift.

It forces radical precision about what gets delivered and how. No open-ended engagements. No volume dependency. No vague advice. Instead: bounded products with fixed output that can be reliably delivered.

That discipline is exactly what this field needs. Superintelligence Relations shouldn't become another consultancy container where everything fits. It must be a measurable, repeatable intervention.

## Mission

> Develop the human capacity to remain clear, responsible, and sovereign in collaboration with superintelligent systems.

## Why this matters beyond business

International cooperation for sustainable development requires trust, shared reality-formation, and decision quality across borders. Superintelligent influence affects all three.

- **Shared decisions**: When international partners each consult their own AI experts, systematic biases can lead to diverging reality-pictures — even with the same data.
- **Trust erosion**: If it's not transparent how AI systems shaped positions, it becomes harder to trust each other's stances as authentically human.
- **Cognitive sovereignty**: Countries and organisations without capacity to recognise superintelligent influence become dependent on those who supply the systems.

Superintelligence Relations is also an international cooperation question: how do we keep human responsibility and defensible choices intact in a world of cognitive asymmetry?
