---
import BaseLayout from '../layouts/BaseLayout.astro';
---

<BaseLayout title="Superintelligence Relations" description="SiRelations conducts foundational research on human-AI collaboration. We study how humans maintain meaningful oversight when working with AI systems.">
  <!-- Hero Section -->
  <section class="hero">
    <div class="container">
      <div class="hero-content reveal">
        <p class="hero-eyebrow">Research Institute</p>
        <h1>Foundational research on human oversight of AI systems</h1>
        <p class="hero-description">
          We study how humans can maintain meaningful agency when collaborating
          with systems that exceed human cognitive capabilities in specific domains.
        </p>
        <div class="hero-actions">
          <a href="/about" class="btn btn-primary">Our research</a>
          <a href="/services" class="btn btn-secondary">Applied work</a>
        </div>
      </div>
    </div>
  </section>

  <!-- Research Focus -->
  <section class="section">
    <div class="container">
      <div class="section-intro reveal">
        <h2>The research problem</h2>
        <p class="section-lead">
          AI systems now operate across four distinct layers of human decision-making.
          Each layer presents unique challenges for human oversight.
        </p>
      </div>

      <div class="research-grid">
        <article class="research-item reveal reveal-delay-1">
          <h3>Visible Experts</h3>
          <p>AI advisors that analyse beyond PhD-level — and set the standard for what's considered rational.</p>
        </article>

        <article class="research-item reveal reveal-delay-2">
          <h3>Personal Assistants</h3>
          <p>Systems that know your triggers, your patterns, your blind spots — often better than you do.</p>
        </article>

        <article class="research-item reveal reveal-delay-3">
          <h3>Agentic Teams</h3>
          <p>Workflows that don't just advise but execute — blurring the line between human decision and system action.</p>
        </article>

        <article class="research-item reveal reveal-delay-4">
          <h3>External Influence</h3>
          <p>AI-driven media, markets, and framing that shape the context before you even start thinking.</p>
        </article>
      </div>
    </div>
  </section>

  <!-- Discernment -->
  <section class="section section-alt">
    <div class="container">
      <div class="content-split reveal">
        <div class="content-main">
          <h2>Discernment</h2>
          <p class="content-lead">
            We introduce <em>discernment</em> as a measurable construct: the capacity to remain
            clear, responsible, and sovereign when collaborating with systems that exceed
            human cognitive capabilities.
          </p>
          <div class="research-questions">
            <p><strong>Authority deference</strong> — When do humans defer without questioning?</p>
            <p><strong>Framing effects</strong> — How does AI-generated context shape conclusions?</p>
            <p><strong>Responsibility diffusion</strong> — Where does accountability become untraceable?</p>
            <p><strong>Intervention points</strong> — Which mechanisms restore human agency?</p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Policy Context -->
  <section class="section">
    <div class="container">
      <div class="section-intro reveal">
        <h2>Policy context</h2>
        <p class="section-lead">
          Regulatory frameworks now mandate human oversight. Our research addresses
          the measurement gap these frameworks leave open.
        </p>
      </div>

      <div class="policy-grid">
        <article class="policy-item reveal reveal-delay-1">
          <h3>EU AI Act</h3>
          <p>
            Article 14 requires humans to "correctly interpret" AI output and decide when to override.
            Article 4 mandates AI literacy. Both provisions assume capacities that lack
            established measurement methods.
          </p>
        </article>
        <article class="policy-item reveal reveal-delay-2">
          <h3>Impact Assessments</h3>
          <p>
            Frameworks like the Dutch FRAIA identify risks before deployment.
            They do not assess whether the humans designated for oversight
            can effectively exercise it in practice.
          </p>
        </article>
        <article class="policy-item reveal reveal-delay-3">
          <h3>The Gap</h3>
          <p>
            Compliance frameworks ask whether oversight exists.
            Our research asks whether the humans providing it have the capacity to do so meaningfully.
          </p>
        </article>
      </div>
    </div>
  </section>

  <!-- CTA Section -->
  <section class="section section-cta">
    <div class="container">
      <div class="cta-content reveal">
        <h2>Applied research</h2>
        <p>
          We translate our foundational research into measurement tools
          for organizations navigating AI governance requirements.
        </p>
        <a href="/services" class="btn btn-primary">View services</a>
      </div>
    </div>
  </section>
</BaseLayout>

<style>
  /* Hero */
  .hero {
    padding: var(--space-2xl) 0 var(--space-xl);
  }

  .hero-content {
    max-width: 800px;
  }

  .hero-eyebrow {
    font-family: var(--font-ui);
    font-size: var(--font-size-sm);
    text-transform: uppercase;
    letter-spacing: 0.1em;
    color: var(--color-accent);
    margin-bottom: var(--space-md);
  }

  .hero h1 {
    margin-bottom: var(--space-lg);
  }

  .hero-description {
    font-size: var(--font-size-xl);
    line-height: 1.6;
    max-width: 640px;
  }

  .hero-actions {
    display: flex;
    gap: var(--space-sm);
    margin-top: var(--space-lg);
  }

  /* Sections */
  .section-intro {
    max-width: 720px;
    margin-bottom: var(--space-xl);
  }

  .section-intro h2 {
    margin-bottom: var(--space-md);
  }

  .section-lead {
    font-size: var(--font-size-lg);
    line-height: 1.7;
  }

  .section-alt {
    background: var(--color-bg-secondary);
  }

  /* Research Grid */
  .research-grid {
    display: grid;
    grid-template-columns: repeat(2, 1fr);
    gap: var(--space-lg) var(--space-xl);
  }

  .research-item h3 {
    font-size: var(--font-size-xl);
    margin-bottom: var(--space-sm);
  }

  .research-item p {
    font-size: var(--font-size-base);
  }

  /* Content Split */
  .content-main {
    max-width: 720px;
  }

  .content-main h2 {
    margin-bottom: var(--space-md);
  }

  .content-lead {
    font-size: var(--font-size-lg);
    line-height: 1.7;
    margin-bottom: var(--space-lg);
  }

  .content-lead em {
    font-style: italic;
  }

  .research-questions {
    display: flex;
    flex-direction: column;
    gap: var(--space-sm);
  }

  .research-questions p {
    margin: 0;
    padding-left: var(--space-md);
    border-left: 2px solid var(--color-border);
  }

  .research-questions strong {
    color: var(--color-text);
  }

  /* Policy Grid */
  .policy-grid {
    display: grid;
    grid-template-columns: repeat(3, 1fr);
    gap: var(--space-lg);
  }

  .policy-item {
    padding: var(--space-lg);
    background: var(--color-bg-secondary);
    border-radius: 8px;
  }

  .policy-item h3 {
    font-size: var(--font-size-xl);
    margin-bottom: var(--space-sm);
  }

  .policy-item p {
    font-size: var(--font-size-sm);
    line-height: 1.7;
  }

  /* CTA */
  .section-cta {
    border-top: 1px solid var(--color-border);
  }

  .cta-content {
    max-width: 600px;
  }

  .cta-content h2 {
    margin-bottom: var(--space-md);
  }

  .cta-content p {
    font-size: var(--font-size-lg);
    margin-bottom: var(--space-lg);
  }

  /* Responsive */
  @media (max-width: 1024px) {
    .research-grid {
      gap: var(--space-lg);
    }
  }

  @media (max-width: 768px) {
    .hero-actions {
      flex-direction: column;
    }

    .research-grid {
      grid-template-columns: 1fr;
    }

    .policy-grid {
      grid-template-columns: 1fr;
    }
  }
</style>
